%\documentclass[manuscript]{biometrika}
\documentclass[article,lineno]{biometrika}
\input{preamble.tex}

\begin{document}

\jname{Biometrika}
%% The year, volume, and number are determined on publication
\jyear{2018}
\jvol{yyy}
\jnum{y}
%% The \doi{...} and \accessdate commands are used by the production team
%\doi{10.1093/biomet/asm023}
\accessdate{yyy}

%% These dates are usually set by the production team
\received{{\rm y} yyy {\rm yyyy}}
\revised{{\rm y} yyy {\rm yyyy}}

%\received{January 2017}
%\revised{April 2017}


%% The left and right page headers are defined here:
\markboth{J. D. Rosenblatt \and J.J. Goeman}{Biometrika style}

%% Here are the title, author names and addresses
\title{Discussion of Sesia et al. 2018 and the Knockoff Framework}

\author{Jonathan D. Rosenblatt}
\affil{Dept. of Industrial Engineering and Management, \\
	Ben Gurion University of the Negev, Israel.\email{johnros@bgu.ac.il}}

\author{\and Jelle J. Goeman}
\affil{TOOD: Jelle \email{J.J.Goeman@lumc.nl}}

\maketitle

%\begin{abstract}
%TODO
%\end{abstract}


\section{On the problem}
% Variable selection with provable error guarantees. Namely, FDR control.

The authors of \cite{SesiaGenehuntinghidden} set out to design a procedure for variable selection with provable statistical guarantees. 
The \emph{knockoff} algorithm proposed by \cite{SesiaGenehuntinghidden}, provably controls the $FDR$ of conditionally independent variables. 
Denoting with $x$ and $y$ the predictor and outcome variables, respectively.
The \emph{false detection proportion}, a.k.a.\ the \emph{false selection proportion}, is defined as $V/R$ where $R$ is the number of variables selected, and $V$ is the number of such variables where $y|x_{-j}$ is independent of $x_j$. 
The knockoff algorithm of \cite{SesiaGenehuntinghidden} provably control the $FDR:=\mathbb{E}[FDP]$, at some user selected magnitude. 

Crucially for our comments:
(1) The $FDR$ is an expectation with respect to variability in $x$ and $y$, i.e., a \emph{random design} guarantee. 
(2) The procedure is \emph{model free}, or \emph{non-parametric} in that nothing is assumed on the parametric form of $y|x$. 
(3) The proofs assume full knowledge of $F_x$, i.e., the joint distribution of predictors, marginalized over $y$.
(4) The method aims at good variable selection, not prediction. 



\section{On the method}
The fundamental idea of the method is to generate variables that have all the properties of the original $x_j$, only that they are conditionally uncorrelated to $y$. 
These are termed \emph{knockoff} variables. 
The method then proceeds to compute a test statistic that captures the difference in the strength of the dependence of the knockoff, and the original variable. 
This statistic is then compared to it resampling distribution: the distribution over resampled knockoffs. 




\subsection{Other Variable Selection Methods}
% stability selection, SURE screening, Banjamini-Gavrilov, BOLASO, hard thresholding, adaptive lasso, …

\subsection{Other Knockoffs}



\subsection{Permutation Testing and Symmetries}



\section{Future Research}
% robustness to $$F_x$$, robustness to true correlations, best statistic for power, algorithms to generate knockoffs, statistics for more than one knockoff,…


\section{On the hypotheses}
% How does knockoff resolve identifiability? Why hypotheses changing between papers? And link to other methods (stability selection, SURE screening, Banjamini-Gavrilov, BOLASO, hard thresholding, adaptive lasso, …).

\section{On the problem setup}
% Random versus fixed design.
% Adequancy for GWAS?



\section*{Acknowledgement}
The authors thank Prof. Yaakov Ritov, Dr. Aldo Solari, Dr. Livio Finos, and ... for fruitful discussions leading to this manuscript. 




\bibliographystyle{biometrika}
\bibliography{paper-ref}



\end{document}
