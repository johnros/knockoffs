%\documentclass[manuscript]{biometrika}
\documentclass[article,lineno]{biometrika}
\input{preamble.tex}
\usepackage{marg}
\begin{document}
	
	\jname{Biometrika}
	%% The year, volume, and number are determined on publication
	\jyear{2018}
	\jvol{yd}
	\jnum{y}
	%% The \doi{...} and \accessdate commands are used by the production team
	%\doi{10.1093/biomet/asm023}
	\accessdate{yd}
	
	%% These dates are usually set by the production team
	\received{{\rm y} yd {\rm YandY}}
	\revised{{\rm y} yd {\rm YandY}}
	
	%\received{January 2017}
	%\revised{April 2017}
	
	
	%% The left and right page headers are defined here:
	\markboth{J. D. Rosenblatt, Y. Ritov, \and J.J. Goeman}{Discussion of Sesia et al. and the Knockoff Framework}
	
	%% Here are the title, author names and addresses
	\title{Discussion of Sesia et al. and the Knockoff Framework}
	
	\author{Jonathan D. Rosenblatt}
	\affil{Dept. of Industrial Engineering and Management, \\
		Ben Gurion University of the Negev, Israel.\email{johnros@bgu.ac.il}}
	
	\author{\and  Ya'\hspace{-0.2em}acov Ritov}
	\affil{Department of Statistics, University of Michigan, USA\email{yritov@umich.edu}}
	
	\author{\and  Jelle J. Goeman}
	\affil{Department of Biomedical Data Sciences,
		Leiden University Medical Center, The Netherlands.\email{J.J.Goeman@lumc.nl}}
	
	
	
	\maketitle
	
	%\begin{abstract}
	%\end{abstract}
	
	
	\section{On the Motivation}
	% Variable selection with provable error guarantees. Namely, FDR control.
	
	The authors of \cite{SesiaGenehuntinghidden} set out to design a procedure for variable selection with provable finite sample statistical guarantees.
	The \emph{knockoff+} algorithm proposed by \cite{SesiaGenehuntinghidden}, provably controls the $\rm{FDR}$ of conditionally independent variables.
	Denoting with $X:=(X_j)_{j=1}^p$ and $Y$ the predictor and outcome variables, respectively.
	The \emph{false discovery proportion}, a.k.a.\ the \emph{false selection proportion}, is defined as $\rm{FDP}:=V/R$ where $R$ is the number of variables selected, and $V$ is the number of falsely selected.
	A false selection defined by \cite{SesiaGenehuntinghidden} to be a selected $X_j$ where $Y|X_{-j}$ is independent of $X_j$.
	The knockoff algorithm of \cite{SesiaGenehuntinghidden} provably controls the $\rm{FDR}:=\mathbb{E}[\rm{FDP}]$, at some user selected magnitude, $q$.
	
	The fundamental idea of the method is to generate another set of variables, the \emph{knockoffs}, that are exchangeable with the original $X_j$s, only that  conditionally on $X$ they are uncorrelated with $Y$.
	The method then proceeds to compute a test statistic that captures the difference between the apparent dependence between $Y$ and $X_j$ and to that of $Y$ with the knockoff $\tilde X_j$.
	
	Crucially for our discussion:
	(1) The $\rm{FDR}$ is an expectation with respect to variability in $X$ and $Y$, i.e., it is a \emph{random design} guarantee.
	(2) The procedure is \emph{model-free}, i.e.\ \emph{non-parametric}, with respect to prediction, in that nothing is assumed on the form of $Y|X$.
	(3) The framework assumes full knowledge of $F_X$, i.e., the joint distribution of predictors, marginalized over $Y$. In application it is based on the assumption that $F_X$ can be estimated well enough to be assumed known.
	(4) The method aims at good variable selection and not prediction, estimation nor ranking.
	
	We think of the method in \cite{SesiaGenehuntinghidden} as an adaptation of \cite{CandesPanninggoldmodelX2018} to genome-wide association studies (GWAS).
	The differences between the two:
	(1) The non-null variables in \cite{CandesPanninggoldmodelX2018} are those that belong to the minimal set that renders all others independent, i.e., the non-null is the Markov-Blanket of $X$ on $Y$.
	In \cite{SesiaGenehuntinghidden}, the non-null variables are those with non-null partial correlations. 
	Under some minimal conditions, that exclude perfectly dependent variables, these two sets are the same.
	(2) In \cite{CandesPanninggoldmodelX2018} $F_X$ is multivariate Gaussian, while in \cite{SesiaGenehuntinghidden}, a hidden Markov model (HMM).
	An important contribution in each paper is an algorithm for sampling knockoffs from the assumed model.
	
	
	
	\section{On the Problem Setup}
	
	The problem setup in \cite{CandesPanninggoldmodelX2018} and \cite{SesiaGenehuntinghidden} deals with random design inference, in a non-parametric model.
	We find this to be a very useful setup for screening problems:
	It is consistent with the random designs typically found in observational studies, and it avoids the very-useful-yet-controversial linearity assumption.
	
	A more surprising component of the problem setup is the knowledge of $F_X$, i.e., the joint distribution of predictors, marginalized over $Y$.
	Many authors would consider this an Oracle assumption, and given the difficulty of estimating joint distributions, an unrealistic one.
	%[We, on the other hand, do not find this such a troubling assumption for the following reasons:
	%(1) In many applications the dimensionality of $F_X$ can be reduced to a tractable one. The HMM assumption of \cite{SesiaGenehuntinghidden} is an example.
	%(2) The preliminary results of \cite{CandesPanninggoldmodelX2018} show that FDR-control is quite robust to errors in $F_X$. We expect this matter to be further investigated in the future.]
	GWAS represents a situation in which much is known about $F_X$, e.g.\ from the HapMap project \citep{Hapmap2003}.
	Other areas of potential application include Semi-Supervised Machine Learning.
	In general high-dimensional data settings, however, $F_X$ has so many parameters that estimating it may turn out be a more difficult problem than estimating the conditional distribution of $Y|X$.
	In all cases, robustness to errors in $F_X$ is crucial for the practical usefulness of the method, and we are happy to see the promising preliminary results of \cite{CandesPanninggoldmodelX2018}.
	On the other hand, the pruning step in the GWAS example of \cite{SesiaGenehuntinghidden} suggests that strong dependencies may adversely affect the performance of the method; both with respect to power, and with respect to the tails of the $\rm{FDP}$ distribution.
	We expect this matter to be further investigated in the future.
	
	
	
	
	\section{Knockoffs as Pseudo-Variables}
	The idea of augmenting design matrices with random variables is not new.
	It has been suggested many times, for the purposes of prediction, variable ranking, large-sample support recovery, etc.
	\cite{TusherSignificanceanalysismicroarrays2001} have already proposed the idea of permuting the original variables for \rm{FDR} control on selected variables.
	While intuitive and elegant, their algorithm did not have any provable guarantees, and implies marginal nulls and not conditional.
	Some more algorithms adding ``fake'', ``phony'', ``probes'' or ``pseudo variables'', are reviewed in \cite{GuyonIntroductionVariableFeature2003}.
	
	Perhaps the most similar work is that of \cite{WuControllingVariableSelection2007}, which not only propose adding ``pseudo-variables'' for the purpose of estimating the variable selection \rm{FDR}, but also require two conditions very similar to the knockoff conditions.
	\cite{WuControllingVariableSelection2007} require that:
	``(A1) real unimportant variables and phony unimportant variables have the same probability of being selected on average'', and
	``(A2) real important variables have the same probability of being selected whether or not phony variables are present''.
	These two conditions cannot be satisfied according to \cite{WuControllingVariableSelection2007}, but they are clearly related to the \emph{pairwise exchangeability} and \emph{nullity condition} in \cite{SesiaGenehuntinghidden} and \cite{CandesPanninggoldmodelX2018}.
	One may thus view the two knockoff conditions as a satisfiable version of Wu's A1 and A2.
	To the credit of \cite{WuControllingVariableSelection2007} we quote their insights, which already hint at what will be later formalized in the knockoff conditions:
	``Permutation produces pseudovariables that when appended to the real data create what
	are essentially matched pairs. To each real variable there corresponds a pseudo variable with identical sample moments and also with preservation of correlations''.
	
	
	
	\section{Conditional Resampling}
	The invariance property in \cite{SesiaGenehuntinghidden} describes so-called \emph{null-invariant transformations} \citep{Goeman2010}:
	the joint distribution of the augmented data $(Y,X,\tilde X)$ is invariant under the transformation $\textrm{swap}(J)$ provided that $J$ is a set of true nulls.
	Known null-invariant transformations, e.g.\ permutations and rotations \citep{Langsrud2005}, existed so far only for null hypotheses about marginal association.
	E.g.\ \citet{TusherSignificanceanalysismicroarrays2001} use a knockoff-like framework to test marginal, not conditional, nulls. This method was recently proven to control tail probabilities of the $\rm{FDP}$ \citep{Hemerik2018}.
	Which null hypothesis is to be preferred? Conditional of marginal?
	Think of two correlated SNPs.
	One causal and the other is not.
	In a screening experiment such as GWAS, we would like both to be selected.
	It thus seems to us that for the purpose of screening, marginal nulls, not conditional, are desirable.
	
	Knockoffs represent, as far as we know, the first null-invariant transformations with respect to conditional nulls rather than marginal nulls.
	Seeing knockoffs as null-invariants opens the way for their more classical use, e.g.\ using multiple random knockoffs for controlling familywise error in the manner of \cite{Westfall1993}. Since familywise error control is the norm in the field of GWAS, the latter would be a worthwhile extension. 
	An alternative approach is resampling from the conditional distribution of $X_j$ given $X_{-j}$. 
	This approach was found to be powerful in \cite[Fig.3]{CandesPanninggoldmodelX2018}, but dismissed there for computational reasons; it was not considered again in \cite{SesiaGenehuntinghidden}. 
	This may be a missed opportunity. 
	Conditional resampling can be done easily in the context of hidden Markov models, where, for example, if $Y\in \{0,1\}$, one can easily test for conditional independence in the $2\times L$ table of $Y$ and $X_j$. 
	More generally, resampling-based methods such as \cite{Westfall1993} are computationally quite efficient, requiring only a small multiple of $\alpha^{-1}$ resampled data sets for powerful FWER control at level $\alpha$. 
	Alternatively, applying early stopping \citep[e.g.][]{jiang2012statistical}, and tail resampling \cite[e.g.][]{yu2011efficient} can be used for additional computational efficiency.
		
	
	
	\section{On Sampling from HMMs}
	In \cite{SesiaGenehuntinghidden} the explanatory variables are considered as HMM: there is a latent Markov process $Z$, such that the observations $X_1,\dots,X_p$ are independent given $Z$ and ${\mathcal L}(X_j|Z)={\mathcal L}(X_j|Z_j)$.
	The knockoff construction algorithm is based on sampling from the Markov process $X\to Z\to \tilde Z\to \tilde X$, so that $(\tilde Z,\tilde X)$ is a knockoff of $(Z,X)$.
	Since we only need that $\tilde{X}$ be a knockoff of $X$, then it is not clear to us why the extra step of a random sample of $\tilde Z$ is needed? Can we not sample directly $X\to Z\to \tilde X$?
	
	Is knowledge of $F_X$ realistic for HMMs?
	Any process can be approximated as a weak limit of a \emph{non-stationary} HMM.
	The difficulty is, of course, with the number of needed parameters.
	For $K$ hidden states, and $L$ output values, then the number of parameters is approximately $p K(K+L-2)$.
	With $n$ and $p$ as in the examples, the demand that the estimated model will be considered as ``known'', enforces quite as small $K$, and hence the HMM assumption is restrictive.
	An HMM is not Markovian, but it is exponentially mixing.
	Practically speaking, $K$ small does not enable medial range non-monotone dependency, as one may find in GWAS due to Linkage-Disequilibrium.
	If $n$ forces $K$ small, dependencies are local, so that marginal and conditional nulls are the same, except locally.
	One may thus test for independence between $Y$ and $X_j$ and some of its neighbors, while ignoring distant $j$'s.
	
	
	
	
	
	\section{Power Considerations and Adversarial Examples}
	
	
	\cite{SesiaGenehuntinghidden} and \cite{CandesPanninggoldmodelX2018} provide compelling power simulations.
	Below we try to design some adversarial examples, where knockoffs may not be favorable.
	From the practitioners' view, a ``knockoff handbook'' will certainly be beneficial.
	
	A non-favorable setup for knockoff is the following. 
	We consider Gaussian $X$s which are highly correlated. High correlation between the $X$ enforces a high correlation between  $X$ and $\tilde X$. 
	In this setup, the knockoff framework may be  worse that the simplest regression with FWER control.
	Why?
	Because the power gain due to FDR control is attenuated by the power cost of the tremendous generality of the knockoff assumptions.
	
	More formally, consider $|\mathcal{S}|\ll p$ and $\mathcal{N}(0,1)$ statistics under the null.	
	Rejecting $q|S|$ true nulls on the average means rejecting variables with test statistics greater than $\sqrt{2\log(p/q|S|)}$ on $Z$ scale.
	A naive Bonferroni correction (which we do not advocate) implies a $\Phi^{-1}(1-q/p)\approx\sqrt{2\log (p/q)}$ rejection cutoff.
	The ratio between the cutoff of some FDR controlling procedure, and FWER control with Bonferroni, is thus $\bigl\{1+\log(|S|)/\log (p/q)\bigr\}^{1/2}$. 
	If $|\mathcal{S}|\ll p$, then FDR has more power than FWER, but not by much. 
	We now need to show that the price of provable FDR control of the knockoffs, may be quite large compared to classical techniques.
	
	We observe $Y=\beta^T X+\epsilon$, $\epsilon\sim \mathcal{N}(0,\sigma^2)$.
	The predictors are correlated in pairs: 
	$X\in R^{2p}$, 
	$X:=(W_j^T)_{j=1}^p; W_j\sim \mathcal{N}_2(0,\Sigma)$, where $\Sigma=\begin{pmatrix}1 & \rho\\\rho &1\end{pmatrix}$.
	\citet{CandesPanninggoldmodelX2018} show that the knockoffs can be given by $(W_j,\tilde W_j)^T$ multivariate normal with $Cov[W_j,\tilde W_j]=\Sigma-\lambda I$ for  $0<\lambda<2(1-\rho)$. 
	We fit the model $Y=\sum W_j^T \gamma_j+\sum \tilde W_j^T \tilde\gamma_j+\epsilon$. 
	Now, by the structure $Var[(X,\tilde X)]$, we see that an efficient estimation of $\gamma_1-\tilde \gamma_1,\dots,\gamma_p-\tilde \gamma_p$ and $\gamma_1+\tilde\gamma_1,\dots,\gamma_p+\tilde\gamma_p$ can be achieved by estimating each of them separately, in particular $\hat\gamma_j -\widehat{\tilde\gamma_j}\sim \mathcal{N}_2(\gamma_j, 2n^{-1}\sigma^2\lambda^{-1} I)$. 
	Compare this to the estimate of the given linear model $Y=\sum W_j^T \gamma_j+\epsilon$, where $\hat\gamma_j\sim\mathcal{N}_2(\gamma_j,n^{-1}\Sigma^{-1})$. 
	If $\rho\approx1$, and $j$ is a null variable then the tails of $|\hat \beta_j|-|\widehat{\tilde\beta_j}|$ behave like the tails of $\hat\beta_j-\widehat{\tilde\beta_j}$. We see thus, that using the knockoff methods increases the effect size needed to achieve a given power by a factor of $\bigl(2(1-\rho^2)/\lambda\bigr)^{1/2}>\bigl(1+\rho\bigr)^{1/2}$.
	
	Combining with the fact that in our setup the FDR and FWER rejection cutoffs are similar, we conclude this is clearly an unfavorable setup for knockoffs. Note that the regular estimator was based only on the \emph{known} distribution of  $X$ and not on the validity model of $Y$ given $X$.
	
	Although this white noise toy model was described in terms of the Gaussian linear model, the idea is probably valid in much more generality. 
	The fundamental observation being that a high correlation within $X$ implies high correlation between $X$ and $\tilde X$, thus between $T_j$ and $\tilde T_j$, even though they should be consistent for different values.
	This may explain why in Sec.7.1, \citet[Sec.7.1]{SesiaGenehuntinghidden} the authors apply a pruning pre-processing stage, which reduces correlations.
	
	
	Another way to design an adversarial example, is simply letting the tails of the null test statistics to be heavier than the alternative.
	The selection cutoff will be driven by the few selected null variables with heavier tails, at the risk of masking non-nulls.
	This is perhaps a less realistic setup than our previous, but will clearly hurt the power of the knockoff procedure.
	
	A standard FDR procedure should have significant level $q$ if all variables are null. The suggested knockoff methods seem to have a problematic behavior if $q|S|<1$. Two methods were suggested in \citet{BarberControllingfalsediscovery2015} and \citet{CandesPanninggoldmodelX2018}. The regular knockoff method has in this situation a significant level of approximately 1/2, while the knockoff+ method has a negligible power of approximately $2^{|S|-1/q}$ no matter how strong is the signal: we should have at least $q^{-1}-|S|$ nulls in the right tail before the first null appears on the left.

	
	
	\section{Future Research}
	
	We find the knockoff framework to be quite exciting.
	Not because it offers solutions to all possible difficulties, but on the contrary: because it sets the stage for many important research questions.
	Some of the following questions are already acknowledged in \citet[Sec.7.2]{CandesPanninggoldmodelX2018}:
	Are error guarantees \textbf{robust} to misspecification of $F_X$?
	What test statistics have more \textbf{power}?
	Knockoffs are not uniquely defined so how to best generate them?
	Do methods defined for other null-invariants, such as permutations, generalize to knockoffs easily?
	How to sample knockoffs efficiently?
	Does screening with knockoffs have more power than the linear model (even if miss-specified)?
	What other algorithms are possible assuming $F_X$ known?
	What can we borrow from the semi-supervised learning literature to the knockoff setup?
	Are the conditional nulls of \cite{SesiaGenehuntinghidden} preferable over marginal nulls such as in \cite{TusherSignificanceanalysismicroarrays2001}?
	
	\cite{DaiknockofffilterFDR2016}, \cite{JansonFamilywiseerrorrate2016}, \cite{ChenAnalysisKnockoffFilter2017}, \cite{ChenPseudoKnockoffFilter2017}, and others, have already started to explore and extend the knockoff framework of \cite{BarberControllingfalsediscovery2015}.
	We expect many such explorations in the upcoming future.
	
	
	
	\section*{Acknowledgement}
	The authors thank  Dr. Aldo Solari, Dr. Livio Finos, Prof. Yuekai Sun, and the students in the University of Michigan Stats 710 class for fruitful discussions leading to this manuscript, while not necessarily agreeing with its conclusions.
	
	
	\bibliographystyle{biometrika}
	\bibliography{paper-ref}
	
	
	
\end{document}
